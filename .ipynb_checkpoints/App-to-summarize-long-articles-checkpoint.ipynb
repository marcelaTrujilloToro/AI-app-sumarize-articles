{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29481709-331f-41fe-8c68-a45c8b94ea89",
   "metadata": {},
   "source": [
    "### Basic Use Case: Summarize a Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be26009-911e-42c5-811e-c4e39b7a1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_= load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75bdf540-b41e-4896-8af6-2998191e1a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv1/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "#instance of model LLM without temperature (is not creative)\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be80ae-e6d3-4da3-9a71-76ec07eee72f",
   "metadata": {},
   "source": [
    "**Load the text file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85626ae2-5c18-4c2b-89da-4f44f542ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/be-good-and-how-not-to-die.txt', 'r') as file:\n",
    "    article = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328db945-6e6f-454d-8c57-a54628510227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c777d3-5b0a-4ab8-acb3-e9250b62a7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be good\n",
      "\n",
      "April 2008(This essay is derived from a talk at the 2008 Startup School.)About a month after we started Y Combinator we came up with the\n",
      "phrase that became our motto: Make something people want.  We've\n",
      "learned a lot since then, but if I were choosing now that's still\n",
      "the one \n"
     ]
    }
   ],
   "source": [
    "print(article[:285])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f41e46c-d32e-4e5e-a86f-010f99464dde",
   "metadata": {},
   "source": [
    "**Check how many tokens are in the article**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f04e2570-96be-4eec-9e76-f6416ac0424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = llm.get_num_tokens(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a0c8cdb-5ee5-4bf1-9c7b-53e19c2f0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 6284 in the article.\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {num_tokens} in the article.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360faa01-cc59-47f6-a1fc-73f3adad20b2",
   "metadata": {},
   "source": [
    "**ChatGPT-3.5 has a context window of 4097 tokens**\n",
    "\n",
    "* This means that we cannot enter all this text in chatGPT to summarize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e90f77-3058-4cb9-9184-267ac87f5dee",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "* Slipt the article in smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12ce2b50-416f-446e-891c-6dd322c49c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4e77470-8e60-4d0d-a552-6f6a12dfef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## configure splitter \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\"], \n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=350\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e298267-9e7e-45ea-ba20-97f86d241073",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fragmenst from article\n",
    "article_chunks = text_splitter.create_documents([article])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f046f72e-ee3a-43fb-ad5d-e6e7d1f0bc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 chunks instead of 1 article\n"
     ]
    }
   ],
   "source": [
    "print(f\"You have {len(article_chunks)} chunks instead of 1 article\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ce631-90e6-4c85-b8fe-1411f86a142d",
   "metadata": {},
   "source": [
    "\n",
    "Load a predefined chain from LangChain: **load_summarize_chain**\n",
    "* which will be used to create the chain. \n",
    "* In this, specify that it should use the instance of the LLM we created earlier and that it should be of the summarize type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e5a7fc9-7b3e-4ad3-98d9-aa539a9c483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0426a-85db-40f6-a50f-6499a60bb590",
   "metadata": {},
   "source": [
    "Apply the chain to the article fragments and run it with ```.run``` on the foundational model we have connected to, which in this case is Chat GPT\n",
    "* That is, we send the 8 fragments to ChatGPT so that it reads each of the fragments and creates a global summary of all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "592c0033-7649-42e5-9f18-a31a7443355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm = llm,\n",
    "    chain_type= \"map_reduce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41a405ab-f994-4553-a0ce-cdf621080332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv1/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "article_summary = chain.run(article_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abab3669-00fe-437d-8dbc-95ea43793b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The article discusses the benefits of being good and doing good in the business world, using examples of successful startups like Google and Craigslist. Being benevolent can attract support and improve decision-making. The author also emphasizes the importance of staying focused and avoiding distractions in order to succeed in a startup. They also mention the role of luck and determination in achieving success. The Octoparts, a promising startup, serves as an example of the importance of perseverance.\n"
     ]
    }
   ],
   "source": [
    "#print summarize\n",
    "print(article_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1325a-7964-4768-9840-3e5c4d5aebc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
